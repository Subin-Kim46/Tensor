{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19e85a50",
   "metadata": {},
   "source": [
    "마디는 1부터 시작\n",
    "박 1/4 , 1/16, 위치은 0부터 시작\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44cf0444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv, argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "#import torchaudio\n",
    "#from torchaudio import transforms\n",
    "import librosa\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "\n",
    "#from whisper.audio import pad_or_trim\n",
    "from io import StringIO\n",
    "from sylk_parser import SylkParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398ed7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = './data/note/rhythmholic/'\n",
    "ogg_path = './data/ogg/'\n",
    "bpm_file_path = './data/음원 리소스 현황.xlsx'\n",
    "note = 'rhythmholic'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735c117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_UT():\n",
    "    \n",
    "    def root_tolist(dir_path):\n",
    "        # 유니코드라 마지막에 슬러시 붙이는걸 추천 ex) dir_path = 'C:/Users/sbkim/T3/code/voice/whisper/data/ogg/'\n",
    "        \n",
    "        f_path = []\n",
    "        \n",
    "        for (root, directories, files) in os.walk(dir_path):\n",
    "            for d in directories:\n",
    "                d_path = os.path.join(root, d)\n",
    "\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                f_path.append(file_path)\n",
    "                \n",
    "        return f_path\n",
    "\n",
    "    def ogg_load(audio_path): #ogg 파일 로드\n",
    "        data, sr = librosa.load(audio_path, sr=22050)\n",
    "        \n",
    "        return data, sr\n",
    "\n",
    "    def slk_to_df(slk_path, col_num): #slk 파일 로드\n",
    "\n",
    "        slk = SylkParser(slk_path,  encoding=\"ANSI\")\n",
    "    \n",
    "        fbuf = StringIO()\n",
    "        slk.to_csv(fbuf)\n",
    "    \n",
    "        test_results = fbuf.getvalue() #slk 파일의 value 추출\n",
    "    \n",
    "        df = test_results.replace('\"','')\n",
    "        df = df.replace('\\n ','').replace(\"\\n\",',').replace(\"enum(n,s,f)\", \"enum\").replace(\"s,\",\"s,0,\") #slk 줄바꿈 될 때 \\n으로 작성된다.\n",
    "    \n",
    "        df = df.split(\",\")\n",
    "    \n",
    "        df_ = []\n",
    "        df_ = pd.DataFrame(df_, columns = df[:col_num])\n",
    "\n",
    "        for i in range(1, len(df) // int(col_num)):\n",
    "            df_.loc[i - int(1)] = df[col_num* i - 1 + 1 : col_num * (i+1)]\n",
    "    \n",
    "        return df_\n",
    "    \n",
    "    def txt_to_df(txt_path): #txt 파일 로드\n",
    "    \n",
    "        with open(txt_path, \"r\", encoding='UTF-8-sig') as file:\n",
    "            strings = file.readlines()\n",
    "        \n",
    "        df = []\n",
    "        df = pd.DataFrame(df, columns = list(strings[0].replace('\\n','').split('\\t')))\n",
    "    \n",
    "        n = 0\n",
    "\n",
    "        for i in strings[2:]:\n",
    "            i = i.replace('\\n','')\n",
    "            i = i.split('\\t')\n",
    "            df.loc[n] = i\n",
    "    \n",
    "            n += 1\n",
    "    \n",
    "        df = df.replace(\"\", \"0\")\n",
    "    \n",
    "        return df\n",
    "    \n",
    "    def per_note_list(bpm_file, note):\n",
    "        bpm_df = pd.read_excel(bpm_file)\n",
    "\n",
    "        bpm_df1 = bpm_df[['ogg', str(note)]]\n",
    "        bpm_df1 = bpm_df1.loc[(bpm_df.ogg !='NONE') & (bpm_df.rhythmholic !='NONE')  ] #ogg and rhyth\n",
    "\n",
    "        bpm_df1.drop([0], axis = 0, inplace=True)\n",
    "\n",
    "        bpm_df1 = bpm_df1.reset_index(drop=True)\n",
    "        bpm_list = bpm_df1['ogg'].values.tolist()\n",
    "\n",
    "        for i in range(len(bpm_list)):\n",
    "            if 'Bpm' in bpm_list[i]:\n",
    "                ogg = bpm_list[i].split('Bpm-')[1]\n",
    "                bpm = ogg.split('.ogg')[0]\n",
    "                if type(bpm) == float:\n",
    "                    bpm_df1.loc[i,'BPM'] = float(bpm)\n",
    "                else:\n",
    "                    bpm_df1.loc[i,'BPM'] = float(bpm.split(' ')[0])\n",
    "\n",
    "\n",
    "        for i in range(len(bpm_df1)):\n",
    "            bpm_df1.loc[i,'ogg'] = bpm_df1.loc[i, str(note)].split('.')[0] + '.ogg'\n",
    "\n",
    "        return bpm_df1\n",
    "    \n",
    "    def remove_audio(audio, sr): #음악 앞 부분에 키를 안치는 ogg 구간 삭제\n",
    "        \n",
    "        tempo = librosa.beat.tempo(onset_envelope=audio, sr=sr)\n",
    "        bar = 60 / tempo * 4\n",
    "        remove_sample = bar * 6 * sr\n",
    "        \n",
    "        total_sample = data[int(remove_sample) + 1 :]\n",
    "        \n",
    "        return total_sample\n",
    "    \n",
    "    def hol_preprocessing(df): #txt파일 라벨링\n",
    "\n",
    "        df = df[df.동작 != 's']\n",
    "        df = df.loc[:,['위치', 'Key']].sort_index()\n",
    "        df.drop([0], axis = 0, inplace=True)\n",
    "        df = df.reset_index(drop=True)\n",
    "    \n",
    "        df_1 = df #새로 생성할 프레임\n",
    "    \n",
    "        for i in range(1, len(df)):\n",
    "            #li = list(filter(lambda x:x%2 == 0, range(int(df.loc[i-1, '위치']) + 2 , int(df.loc[i, '위치']))))\n",
    "            li = list(filter(lambda x : x , range(int(df.loc[i-1, '위치']) + 1 , int(df.loc[i, '위치']))))\n",
    "            \n",
    "            #동작이 s인거 빼고 위치가 다 짝수인줄 알았지만 아니였다! 홀수도 있기때문에 기존에 2로 나눴지만, 1당 key가 찍히는걸로 수정\n",
    "            \n",
    "            for j in li:\n",
    "                fi_df = pd.DataFrame([[j, 0]], columns = df.columns)\n",
    "                df_1 = pd.concat([df_1, fi_df], ignore_index = True)\n",
    "    \n",
    "        df_1 = df_1.astype('int')\n",
    "        df_1 = df_1.sort_values('위치')\n",
    "        df_1 = df_1.reset_index(drop=True)\n",
    "        \n",
    "        #df_1.loc[df_1[\"Key\"] == 4, \"Key\"] = 1\n",
    "        #df_1.loc[df_1[\"Key\"] == 6, \"Key\"] = 2 token으로 대체\n",
    "    \n",
    "        return df_1\n",
    "    \n",
    "    def label_tolist(df): #라벨 to list & 시작 부분부터 마디 시작까지 zero padding\n",
    "        \n",
    "        zero_list = list(int(df.loc[0,\"위치\"]) * '0')\n",
    "        li = list(df.loc[:, \"Key\"])\n",
    "\n",
    "        total_li = zero_list + li\n",
    "        #li = df.loc[:, \"Key\"]\n",
    "        \n",
    "        return total_li\n",
    "    \n",
    "    def Mel_S(y, sr, frame_length = 0.025, frame_stride = 0.010): #mel_spectrogram\n",
    "        # mel-spectrogram\n",
    "\n",
    "        input_nfft = int(round(sr*frame_length))\n",
    "        input_stride = int(round(sr*frame_stride))\n",
    "\n",
    "        S = librosa.feature.melspectrogram(y=y, n_mels=64, n_fft=input_nfft, hop_length=input_stride)\n",
    "\n",
    "        return S\n",
    "    \n",
    "    def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2): #spec aug\n",
    "        _, n_mels, n_steps = spec.shape\n",
    "        mask_value = spec.mean()\n",
    "        aug_spec = spec\n",
    "\n",
    "        freq_mask_param = max_mask_pct * n_mels\n",
    "        for _ in range(n_freq_masks):\n",
    "            aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        time_mask_param = max_mask_pct * n_steps\n",
    "        for _ in range(n_time_masks):\n",
    "            aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        return aug_spec\n",
    "    \n",
    "\n",
    "    def df_method(txt_df):\n",
    "        for i in range(len(txt_df)):\n",
    "                txt_df.loc[i, note] = str(txt_path) + txt_df.loc[i, note]\n",
    "                #print(txt_df.loc[i, note])\n",
    "        txt_list = list(txt_df.loc[:,note])\n",
    "\n",
    "        return txt_list\n",
    "    \n",
    "    def path_method(txt_path):\n",
    "        txt_files = Data_UT.root_tolist(txt_path)\n",
    "\n",
    "        #print(ogg_files)\n",
    "        txt_list = []\n",
    "            \n",
    "\n",
    "        for k in txt_files:\n",
    "            if k[-4:] == '.slk':\n",
    "                txt_list.append(k)\n",
    "        return txt_list\n",
    "\n",
    "\n",
    "    def extract_label(txt_list,  note = note):\n",
    "        \n",
    "\n",
    "        total_label = []\n",
    "        total_num = []\n",
    "        error_list = []\n",
    "        total_df = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(txt_list)):\n",
    "\n",
    "            df = Data_UT.slk_to_df(txt_list[i],6)\n",
    "            #print(df)\n",
    "            txt_df1 = Data_UT.hol_preprocessing(df)\n",
    "\n",
    "            txt_df1 = Data_UT.label_tolist(txt_df1)\n",
    "            result = ''.join(map(str, txt_df1))\n",
    "            num = len(result)\n",
    "\n",
    "\n",
    "            total_label.append(result)\n",
    "            total_num.append(int(num))\n",
    "\n",
    "        total_df = pd.DataFrame({str(note) : txt_list ,'label': total_label, 'len' : total_num})\n",
    "        \n",
    "\n",
    "        return total_df\n",
    "\n",
    "    def label_padding(total_df): #label 뒷 부분 padding\n",
    "        \n",
    "        max_num = max(total_df.loc[:,'len'])\n",
    "\n",
    "        for n in range(len(total_df)):\n",
    "            if total_df.loc[n, 'len'] < max_num:\n",
    "\n",
    "                sub_num = max_num - total_df.loc[n, 'len']\n",
    "                sub_zero = '0' * int(sub_num)\n",
    "                total_label = str(total_df.loc[n, 'label']) + sub_zero\n",
    "                total_df.loc[n, 'label'] = total_label\n",
    "\n",
    "        \n",
    "        return total_df \n",
    "    \n",
    "    def audio_sample_padding(audio, max_num):\n",
    "        audio_ = librosa.util.fix_length(audio, size = max_num)\n",
    "        return audio_\n",
    "    \n",
    "\n",
    "    def check_audio_len(df, note = note):\n",
    "        length = 0\n",
    "        ogg_path_list = list(df.loc[:,str(note)])\n",
    "        except_ogg = []\n",
    "\n",
    "        for i in ogg_path_list:\n",
    "            i_ = i.replace('note/rhythmholic','ogg').replace('_hol','').replace('.slk','.ogg')\n",
    "            audio, sr = Data_UT.ogg_load(i_)\n",
    "\n",
    "            S = librosa.feature.melspectrogram(y=audio, sr = sr)\n",
    "\n",
    "            aud_length = np.shape(S)[1]\n",
    "\n",
    "            if aud_length > length:\n",
    "                length = aud_length\n",
    "\n",
    "\n",
    "            '''\n",
    "            #일반 길이에서 짜르는거 잘못한거!!!\n",
    "            audio_sample = len(audio)\n",
    "            \n",
    "            if audio_sample <= 5292000: #22050 * 240 (sample_rate * 초)\n",
    "                if audio_sample > length:\n",
    "                    length = len(audio)\n",
    "            else:\n",
    "                except_ogg.append(i_)\n",
    "\n",
    "\n",
    "        \n",
    "        li = [] #except_ogg_list\n",
    "\n",
    "        for i in except_ogg:\n",
    "            i = i.replace('.ogg','_hol.slk').replace('ogg','note/rhythmholic')\n",
    "            li.append(i)\n",
    "            '''        \n",
    "\n",
    "        return length\n",
    "\n",
    "    def except_ogg_from_df(df, except_ogg, note = note):\n",
    "\n",
    "        df = df.loc[~(df[note].isin(except_ogg))].reset_index(drop=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_ogg_path(df):\n",
    "    \n",
    "        ogg_path = []\n",
    "        for i, row in df.iterrows():\n",
    "            li = row.rhythmholic\n",
    "            li = li.replace('note/rhythmholic','ogg').replace('_hol','').replace('.slk','.ogg')\n",
    "            ogg_path.append(li)\n",
    "\n",
    "        return ogg_path    \n",
    "\n",
    "    def total_audio(path, max_num):\n",
    "\n",
    "        audio, sr = Data_UT.ogg_load(path)\n",
    "\n",
    "        S = librosa.feature.melspectrogram(y=audio, sr = sr)\n",
    "        S_pad = Data_UT.audio_sample_padding(S, max_num)\n",
    "            \n",
    "        return S_pad\n",
    "        #return S\n",
    "\n",
    "    def concat_df(audio_sample, df):\n",
    "        label = df[['label']]\n",
    "        audio_df = pd.DataFrame({'audio' : audio_sample})\n",
    "\n",
    "        total_data = pd.concat([audio_df, label], axis= 1)\n",
    "        return total_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d372341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_load():\n",
    "    def total_data_load(bpm_file, note):\n",
    "        df = Data_UT.per_note_list(bpm_file, note)[:10] #개수 제한\n",
    "        df_list = Data_UT.df_method(df)\n",
    "        label_df = Data_UT.extract_label(df_list, note)\n",
    "        #label_df1 = Data_UT.label_padding(label_df)\n",
    "        max_len = Data_UT.check_audio_len(label_df)\n",
    "        #label_df1 = Data_UT.except_ogg_from_df(label_df, except_ogg)\n",
    "        label_df1 = Data_UT.label_padding(label_df)\n",
    "\n",
    "        return label_df1, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70968b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, max_len = data_load.total_data_load(bpm_file_path, note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167a5196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10533"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94a738b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rhythmholic</th>\n",
       "      <th>label</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/note/rhythmholic/k5723_hol.slk</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/note/rhythmholic/k5724_hol.slk</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/note/rhythmholic/k5725_hol.slk</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>2157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/note/rhythmholic/k5726_hol.slk</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/note/rhythmholic/k5728_hol.slk</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./data/note/rhythmholic/k5730_hol.slk</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./data/note/rhythmholic/k5732_hol.slk</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./data/note/rhythmholic/k5733_hol.slk</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./data/note/rhythmholic/k5735_hol.slk</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./data/note/rhythmholic/k5736_hol.slk</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             rhythmholic   \n",
       "0  ./data/note/rhythmholic/k5723_hol.slk  \\\n",
       "1  ./data/note/rhythmholic/k5724_hol.slk   \n",
       "2  ./data/note/rhythmholic/k5725_hol.slk   \n",
       "3  ./data/note/rhythmholic/k5726_hol.slk   \n",
       "4  ./data/note/rhythmholic/k5728_hol.slk   \n",
       "5  ./data/note/rhythmholic/k5730_hol.slk   \n",
       "6  ./data/note/rhythmholic/k5732_hol.slk   \n",
       "7  ./data/note/rhythmholic/k5733_hol.slk   \n",
       "8  ./data/note/rhythmholic/k5735_hol.slk   \n",
       "9  ./data/note/rhythmholic/k5736_hol.slk   \n",
       "\n",
       "                                               label   len  \n",
       "0  0000000000000000000000000000000000000000000000...  1327  \n",
       "1  0000000000000000000000000000000000000000000000...  1085  \n",
       "2  0000000000000000000000000000000000000000000000...  2157  \n",
       "3  0000000000000000000000000000000000000000000000...  1261  \n",
       "4  0000000000000000000000000000000000000000000000...  1197  \n",
       "5  0000000000000000000000000000000000000000000000...  1597  \n",
       "6  0000000000000000000000000000000000000000000000...  1213  \n",
       "7  0000000000000000000000000000000000000000000000...  1647  \n",
       "8  0000000000000000000000000000000000000000000000...  1325  \n",
       "9  0000000000000000000000000000000000000000000000...  1069  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ed11c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df.loc[i, 'rhythmholic'] = df.loc[i, 'rhythmholic'].replace('note/rhythmholic','ogg').replace('_hol','').replace('.slk','.ogg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5822c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rhythmholic</th>\n",
       "      <th>label</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/ogg/k5723.ogg</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/ogg/k5724.ogg</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/ogg/k5725.ogg</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>2157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/ogg/k5726.ogg</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/ogg/k5728.ogg</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./data/ogg/k5730.ogg</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./data/ogg/k5732.ogg</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./data/ogg/k5733.ogg</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./data/ogg/k5735.ogg</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./data/ogg/k5736.ogg</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rhythmholic                                              label   \n",
       "0  ./data/ogg/k5723.ogg  0000000000000000000000000000000000000000000000...  \\\n",
       "1  ./data/ogg/k5724.ogg  0000000000000000000000000000000000000000000000...   \n",
       "2  ./data/ogg/k5725.ogg  0000000000000000000000000000000000000000000000...   \n",
       "3  ./data/ogg/k5726.ogg  0000000000000000000000000000000000000000000000...   \n",
       "4  ./data/ogg/k5728.ogg  0000000000000000000000000000000000000000000000...   \n",
       "5  ./data/ogg/k5730.ogg  0000000000000000000000000000000000000000000000...   \n",
       "6  ./data/ogg/k5732.ogg  0000000000000000000000000000000000000000000000...   \n",
       "7  ./data/ogg/k5733.ogg  0000000000000000000000000000000000000000000000...   \n",
       "8  ./data/ogg/k5735.ogg  0000000000000000000000000000000000000000000000...   \n",
       "9  ./data/ogg/k5736.ogg  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "    len  \n",
       "0  1327  \n",
       "1  1085  \n",
       "2  2157  \n",
       "3  1261  \n",
       "4  1197  \n",
       "5  1597  \n",
       "6  1213  \n",
       "7  1647  \n",
       "8  1325  \n",
       "9  1069  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55546f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9e5393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hole_Data(Dataset):\n",
    "    \n",
    "    def __init__(self, df, max_len, ogg_list):\n",
    "\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "        self.ogg_list = ogg_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        audio = Data_UT.total_audio(self.ogg_list[idx], self.max_len)\n",
    "        #print(audio.size())\n",
    "\n",
    "        label = self.df.loc[idx,'label']\n",
    "        label = torch.tensor(list(map(int, label)))\n",
    "        #label = torch.stack(label, dim=0)\n",
    "        #return audio\n",
    "        #return {'audio': audio, 'label' : label}\n",
    "        return (audio, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "174d8ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ogg_list = Data_UT.get_ogg_path(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "291077dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/ogg/k5723.ogg',\n",
       " './data/ogg/k5724.ogg',\n",
       " './data/ogg/k5725.ogg',\n",
       " './data/ogg/k5726.ogg',\n",
       " './data/ogg/k5728.ogg',\n",
       " './data/ogg/k5730.ogg',\n",
       " './data/ogg/k5732.ogg',\n",
       " './data/ogg/k5733.ogg',\n",
       " './data/ogg/k5735.ogg',\n",
       " './data/ogg/k5736.ogg']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ogg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1213aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = hole_Data(df, max_len, ogg_list)\n",
    "\n",
    "train_dl_ = DataLoader(train_dl, batch_size=2, shuffle= True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c8d8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2157])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_dl[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b1f712a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1829"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dl[0][1]).count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a26bb152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10533"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbb6909d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2157])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_dl[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5b164ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"label\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df8a461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = extract_all_chars(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "988ea88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab': [[' ', '0', '6', '4']],\n",
       " 'all_text': ['000000000000000000000000000000000000000000000000000000000000000000000000000000004060406040006000406040604000600060404060600040006040406060004000400060406060400040006040606040000000000000000000000000000000000040004060406040004000406040604000600040606040400060004060604040004060604040006000406060404000600000000000000000000000000000000000400060406000400040006040600040006000406040006000600040604000600040006040604060004000604060406000000000000000000000000000000000004000400060006040400040006000604060004000600060406000400060006040400060006000404040006000600040400000000000000000000000000000000040604060400060004060406040006000604040606000400060404060600040004000604060604000400060406060400000000000000000000000000000000000400040604060400040004060406040006000406060404000600040606040400040606040400060004060604040006000000000000000000000000000000000004000604060004000400060406000400060004060400060006000406040006000400060406040600040006040604060000000000000000000000000000000000040004000600060404000400060006040600040006000604060004000600060404000600060004000400060006000400000000000000000000000000000000000400060406000400040006040600040006000406040006000600040604000600040006040604060004000604060406000000000000000000000000000000000004000400060006040400040006000604060004000600060406000400060006040400060006000404040006000600040400000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000604060004060400060406000406040004060600040406000406060004040600060604000400060006060400040006000000000000000000000000000000000006040406040004000604040604000400040406000604060004040600060406000606040406000600060604040600060000000000000000000000000000000000060004000406040006000400040604000404060604000600040406060400060006040604060006000604060406000600000000000000000000000000000000000604060004060400060406000406040004060600040406000406060004040600060604000400060006060400040006000000000000000000000000000000000006040406040004000604040604000400040406000604060004040600060406000606040406000600060604040600060000000000000000000000000000000000060004000600040006000400060004000400060004000600040006000400060006000400040006000600040004000600000000000000000000000000000000000604040604000400060404060400040004040600060406000404060006040600060604040600060006060404060006000000000000000000000000000000000006000400040604000600040004060400040406060400060004040606040006000604060406000600060406040600060000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000406040604000600040604060400060006000404060604000600040406060400040006000400060004000600040006000000000000000000000000000000000004060604040006000406060404000600060004060406040006000406040604000400040006000600040004000600060000000000000000000000000000000000040004060604040004000406060404000600060404060600060006040406060004000606040604000400060604060400000000000000000000000000000000000406040006040600040604000604060006000406040006000600040604000600040606000404060004060600040406000000000000000000000000000000000004040600040606000404060004060600060006040400060006000604040006000404060004060400040406000406040000000000000000000000000000000000040006000400060004000600040006000600060004000400060006000400040004000600060004000400060006000400000000000000000000000000000000000406060404000600040606040400060006000406040604000600040604060400040004000600060004000400060006000000000000000000000000000000000004000406060404000400040606040400060006040406060006000604040606000400060604060400040006060406040000000000000000000000000000000000040604000604060004060400060406000600040604000600060004060400060004060600040406000406060004040600000000000000000000000000000000000404060004060600040406000406060006000604040006000600060404000600040406000406040004040600040604000000000000000000000000000000000004000600040006000400060004000600060006000400040006000600040004000400060006000400040006000600040000000000000000000000000000000000040004000600060004000400060006000600040006000400060004000600040004000600040006000400060004000600000000000000000000000000000000000406040006040600040604000604060006000406040006000600040604000600040606000404060004060600040406000000000000000000000000000000000004040600040606000404060004060600060006040400060006000604040006000404060004060400040406000406040000000000000000000000000000000000040006000400060004000600040006000600060004000400060006000400040004000600060004000400060006000400000000000000000000000000000000000400040006000600040004000600060006000400060004000600040006000400040006000400060004000600040006 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000606040406000400060604040600040004000600040604000400060004060400060004040606040006000404060604000000000000000000000000000000000006000400060604040600040006060404040004000606040004000400060604000600040006040604060004000604060400000000000000000000000000000000060406000406040006040600040604000406040604000400040604060400040006000406060404000600040606040400000000000000000000000000000000000604040006060400060404000606040004040606040004000404060604000400060004000604040606000400060404060000000000000000000000000000000006060404060004000606040406000400040006000406040004000600040604000600040406060400060004040606040000000000000000000000000000000000060004000606040406000400060604040400040006060400040004000606040006000400060406040600040006040604000000000000000000000000000000000604060004060400060406000406040004060406040004000406040604000400060004060604040006000406060404000000000000000000000000000000000006040400060604000604040006060400040406060400040004040606040004000600040006040406060004000604040600000000000000000000000000000000060004000600040006000400060004000400060004000600040006000400060006000400040006000600040004000600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 000000000000000000000000000000000000000000000000000000000000000000000000000000006040600040604000604060004060400040406060400060004040606040006000606040004040600060604000404060000000000000000000000000000000000060404000600040006040400060004000406040006040600040604000604060006060400060006000606040006000600000000000000000000000000000000000604060406000400060406040600040004000600060406040400060006040604060604040600060006060404060006000000000000000000000000000000000006000400060004000600040006000400040006000400060004000600040006000600040004000600060004000400060000000000000000000000000000000000060406000406040006040600040604000404060604000600040406060400060006060400040406000606040004040600000000000000000000000000000000000604060406000400060406040600040004000600060406040400060006040604060604040600060006060404060006000000000000000000000000000000000006000400060004000600040006000400040006000400060004000600040006000600040004000600060004000400060000000000000000000000000000000000060404000600040006040400060004000406040006040600040604000604060006060400060006000606040006000600000000000000000000000000000000000604060406000400060406040600040004000600060406040400060006040604060604040600060006060404060006000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000600060004000400060006000400040004000600040006000400060004000600060604060400040006060406040004000000000000000000000000000000000006040606040004000604060604000400040006040600040004000604060004000604060406000400060406040600040000000000000000000000000000000000060404060600040006040406060004000400060604040600040006060404060006000404060604040600040406060404000000000000000000000000000000000604060604000400060406060400040004000600060004000400060006000400060406000604060406040600060406040000000000000000000000000000000006040400060604040604040006060404040406040600040004040604060004000604040604000600060404060400060000000000000000000000000000000000060604040600060006060404060006000400060004000600040006000400060006000406040604000600040604060400000000000000000000000000000000000604060604000400060406060400040004000604060004000400060406000400060406040600040006040604060004000000000000000000000000000000000006040406060004000604040606000400040006060404060004000606040406000600040406060404060004040606040400000000000000000000000000000000060406060400040006040606040004000400060006000400040006000600040006040600060406040604060006040604000000000000000000000000000000000604040006060404060404000606040404040604060004000404060406000400060404060400060006040406040006000000000000000000000000000000000006060404060006000606040406000600040006000400060004000600040006000600040604060400060004060406040000000000000000000000000000000000060006000400040006000600040004000400060004000600040006000400060006000400060004000600040006000400000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000400060406000400040006040600040006000604040006000600060404000600040604060400060004060406040006000000000000000000000000000000000004000406060004000400040606000400060004060400060006000406040006000406060404000600040606040400060000000000000000000000000000000000040604040600040004060404060004000604040606000400060404060600040004040604060006000404060406000600000000000000000000000000000000000406040006040600040604000604060006040604060004000604060406000400040406000406060004040600040606000000000000000000000000000000000004000600060004000400060006000400060004000400060006000400040006000400040006000600040004000600060000000000000000000000000000000000040006040600040004000604060004000600060404000600060006040400060004060406040006000406040604000600000000000000000000000000000000000400040606000400040004060600040006000406040006000600040604000600040606040400060004060604040006000000000000000000000000000000000004060404060004000406040406000400060404060600040006040406060004000404060406000600040406040600060000000000000000000000000000000000040604000604060004060400060406000604060406000400060406040600040004040600040606000404060004060600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000400060406040600040006040604060006040400060604040604040006060404040004060604060004000406060406000000000000000000000000000000000004000604060004000400060406000400060604040606040006060404060604000400040606000400040004060600040000000000000000000000000000000000040006040406060004000604040606000604060004000400060406000400040004000604060604000400060406060400000000000000000000000000000000000400060004060604040006000406060406060400040006000606040004000600040004000606040404000400060604040000000000000000000000000000000004000600040006000400060004000600060004000600040006000400060004000400040606040600040004060604060000000000000000000000000000000000040006040604060004000604060406000604040006060404060404000606040404000406060406000400040606040600000000000000000000000000000000000400060406000400040006040600040006060404060604000606040406060400040004060600040004000406060004000000000000000000000000000000000004000604040606000400060404060600060406000400040006040600040004000400060406060400040006040606040000000000000000000000000000000000040006000406060404000600040606040606040004000600060604000400060004000400060604040400040006060404000000000000000000000000000000000400060006000400040006000600040006000400040006000600040004000600040004060604060004000406060406000000000000000000000000000000000004000604040606000400060404060600060406000400040006040600040004000400060406060400040006040606040000000000000000000000000000000000040006000406060404000600040606040606040004000600060604000400060004000400060604040400040006060404000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 000000000000000000000000000000000000000000000000000000000000000000000000000000004060600040406000406060004040600060406000406040006040600040604000406040406000600040604040600060000000000000000000000000000000000040604000604060004060400060406000600040604060400060004060406040004060406040006000406040604000600000000000000000000000000000000000404060604000400040406060400040006000400060604040600040006060404040006000400060004000600040006000000000000000000000000000000000004060400040004000406040004000400060406000600040006040600060004000400060006000400040006000600040000000000000000000000000000000000040606000404060004060600040406000604060004060400060406000406040004060404060006000406040406000600000000000000000000000000000000000406040006040600040604000604060006000406040604000600040604060400040604060400060004060406040006000000000000000000000000000000000004040606040004000404060604000400060004000606040406000400060604040400060004000600040006000400060000000000000000000000000000000000040604060400040004060406040004000600040006040604060004000604060404000400060006000400040006000600000000000000000000000000000000000406040006000400040604000600040006040400060004000604040006000400040004000600060004000400060006000000000000000000000000000000000004060400040004000406040004000400060406000600040006040600060004000400060006000400040006000600040000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 000000000000000000000000000000000000000000000000000000000000000000000000000000006060400060004000606040006000400040604060400060004060406040006000604060004000400060406000400040000000000000000000000000000000000060404060400040006040406040004000400060004060604040006000406060406040600040604000604060004060400000000000000000000000000000000000606040006060404060604000606040404060400040606040406040004060604060406000404060606040600040406060000000000000000000000000000000006000400060004000600040006000400040004000600060004000400060006000600060004000400060006000400040000000000000000000000000000000000060604000600040006060400060004000406040604000600040604060400060006040600040004000604060004000400000000000000000000000000000000000604040604000400060404060400040004000600040606040400060004060604060406000406040006040600040604000000000000000000000000000000000006060400060604040606040006060404040604000406060404060400040606040604060004040606060406000404060600000000000000000000000000000000060004000600040006000400060004000400040006000600040004000600060006000600040004000600060004000400000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000040604000604060004060400060406000604040006060400060404000606040004060604060406000406060406040600000000000000000000000000000000000400040006040604040004000604060406040406060004000604040606000400040006000604040604000600060404060000000000000000000000000000000004060406040006000406040604000600060004060604060006000406060406000406060404000600040606040400060000000000000000000000000000000000040006060404060004000606040406000600060406040600060006040604060004000604060004000400060406000400000000000000000000000000000000000406040004040606040604000404060606040600060406040604060006040604040006060406040004000606040604000000000000000000000000000000000004060400060406000406040006040600060404000606040006040400060604000406060406040600040606040604060000000000000000000000000000000000040004000604060404000400060406040604040606000400060404060600040004000600060404060400060006040406000000000000000000000000000000000406040604000600040604060400060006000406060406000600040606040600040606040400060004060604040006000000000000000000000000000000000004000606040406000400060604040600060006040604060006000604060406000400060406000400040006040600040000000000000000000000000000000000040604000404060604060400040406060604060006040604060406000604060404000606040604000400060604060400000000000000000000000000000000000400040006000600040004000600060006000600040004000600060004000400040006000400060004000600040006000000000000000000000000000000000004060400040406060406040004040606060406000604060406040600060406040400060604060400040006060406040000000000000000000000000000000000040604000604060004060400060406000604040006060400060404000606040004060604060406000406060406040600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61653055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0, '6': 1, ' ': 2, '4': 3}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = list(set(vocabs[\"vocab\"][0]) | set(vocabs[\"vocab\"][0]))\n",
    "\n",
    "vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dce8131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]\n",
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8594587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe9f411c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0, '6': 1, '4': 3, '|': 2, '[UNK]': 4, '[PAD]': 5}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90eb97e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyCTCDecoder(torch.nn.Module):\n",
    "    def __init__(self, labels, blank=0):\n",
    "        super().__init__()\n",
    "        self.labels = labels\n",
    "        self.blank = blank\n",
    "\n",
    "    def forward(self, emission: torch.Tensor) -> str:\n",
    "        \"\"\"Given a sequence emission over labels, get the best path string\n",
    "        Args:\n",
    "          emission (Tensor): Logit tensors. Shape `[num_seq, num_label]`.\n",
    "\n",
    "        Returns:\n",
    "          str: The resulting transcript\n",
    "        \"\"\"\n",
    "        indices = torch.argmax(emission, dim=-1)  # [num_seq,]\n",
    "        indices = torch.unique_consecutive(indices, dim=-1)\n",
    "        indices = [i for i in indices if i != self.blank]\n",
    "        return \"\".join([self.labels[i] for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28c53837",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = GreedyCTCDecoder(labels=vocab_dict).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26f14370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2157])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_dl[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "646c3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conformer.model import Conformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf3ee916",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()  \n",
    "device = torch.device('cuda' if cuda else 'cpu')\n",
    "\n",
    "criterion = nn.CTCLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3857768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size, sequence_length, dim = 2, max_len, 128\n",
    "batch_size, dim = 4, 80\n",
    "input_length = torch.LongTensor([2157, 3, 1])\n",
    "target_length = torch.LongTensor([2157])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "570ab1b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Conformer(num_classes=2157, \n",
    "                  input_dim=dim, \n",
    "                  encoder_dim=32, \n",
    "                  num_encoder_layers=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28fe8c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (62x21056 and 608x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[39m#time.sleep(0.1)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m num_epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m\n\u001b[1;32m---> 58\u001b[0m a \u001b[39m=\u001b[39m training(model, train_dl_, input_length, target_length, num_epochs)\n",
      "Cell \u001b[1;32mIn[19], line 22\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(model, train_dl, input_lengths, target_lengths, num_epochs)\u001b[0m\n\u001b[0;32m     19\u001b[0m inputs \u001b[39m=\u001b[39m (inputs \u001b[39m-\u001b[39m inputs_m) \u001b[39m/\u001b[39m inputs_s\n\u001b[0;32m     21\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 22\u001b[0m outputs, output_lengths \u001b[39m=\u001b[39m model(inputs, input_lengths)\n\u001b[0;32m     23\u001b[0m \u001b[39m#print(outputs)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m#trans = decoder(outputs)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32mc:\\Users\\sbkim\\T3\\code\\voice\\wav2vec\\wav2vec\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sbkim\\T3\\code\\voice\\wav2vec\\conformer\\model.py:105\u001b[0m, in \u001b[0;36mConformer.forward\u001b[1;34m(self, inputs, input_lengths)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs: Tensor, input_lengths: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[0;32m     94\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39m    Forward propagate a `inputs` and `targets` pair for training.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39m        * predictions (torch.FloatTensor): Result of model predictions.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     encoder_outputs, encoder_output_lengths \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(inputs, input_lengths)\n\u001b[0;32m    106\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(encoder_outputs)\n\u001b[0;32m    107\u001b[0m     outputs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mlog_softmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sbkim\\T3\\code\\voice\\wav2vec\\wav2vec\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sbkim\\T3\\code\\voice\\wav2vec\\conformer\\encoder.py:203\u001b[0m, in \u001b[0;36mConformerEncoder.forward\u001b[1;34m(self, inputs, input_lengths)\u001b[0m\n\u001b[0;32m    200\u001b[0m outputs, output_lengths \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_subsample(inputs, input_lengths)\n\u001b[0;32m    201\u001b[0m \u001b[39m#print(np.shape(outputs))\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_projection(outputs)\n\u001b[0;32m    204\u001b[0m \u001b[39m#print(\"aaaaaaaaaaaaaaaa\")\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n",
      "File \u001b[1;32mc:\\Users\\sbkim\\T3\\code\\voice\\wav2vec\\wav2vec\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sbkim\\T3\\code\\voice\\wav2vec\\wav2vec\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sbkim\\T3\\code\\voice\\wav2vec\\wav2vec\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sbkim\\T3\\code\\voice\\wav2vec\\conformer\\modules.py:49\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear(x)\n",
      "File \u001b[1;32mc:\\Users\\sbkim\\T3\\code\\voice\\wav2vec\\wav2vec\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sbkim\\T3\\code\\voice\\wav2vec\\wav2vec\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (62x21056 and 608x32)"
     ]
    }
   ],
   "source": [
    "def training(model, train_dl, input_lengths, target_lengths, num_epochs):\n",
    "    pred = []\n",
    "    #criterion = nn.CTCLoss()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #criterion = nn.NLLLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.00005)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.00005)\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), mininterval=0.01):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = 0\n",
    "        total_prediction = 0\n",
    "\n",
    "        for i, (data,label) in enumerate(train_dl):\n",
    "            labels = label.to(device)\n",
    "            inputs = data.to(device)\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, output_lengths = model(inputs, input_lengths)\n",
    "            #print(outputs)\n",
    "            #trans = decoder(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            #loss = F.softmax(outputs, dim =1)\n",
    "            #print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            running_loss += loss.item()\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            pred.append(outputs)\n",
    "            #print(\"prediction\")\n",
    "            #print(prediction)\n",
    "            #print(\"label\")\n",
    "            #print(label)\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[1]\n",
    "            #print(correct_prediction)\n",
    "    \n",
    "        #optimizer.swap_swa_sgd()\n",
    "        num_batches = len(train_dl)\n",
    "        #print(num_batches)\n",
    "        #avg_loss = criterion(outputs.transpose(0, 1), targets = labels, output_lengths = output_lengths, target_lengths = target_lengths)\n",
    "        avg_loss = running_loss / num_batches\n",
    "\n",
    "\n",
    "        acc = correct_prediction/total_prediction\n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss:.4f}, Accuracy: {acc:.4f}')\n",
    "\n",
    "    print('Finished Training')\n",
    "    return pred\n",
    "\n",
    "        #time.sleep(0.1)\n",
    "    \n",
    "num_epochs=5\n",
    "a = training(model, train_dl_, input_length, target_length, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08200c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef1ca5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.7976, -7.8206, -7.6567,  ..., -7.6571, -7.6575, -7.7462],\n",
       "         [-7.7895, -7.7897, -7.5845,  ..., -7.6604, -7.6774, -7.7719],\n",
       "         [-7.8018, -7.8132, -7.5837,  ..., -7.6781, -7.5985, -7.7428],\n",
       "         ...,\n",
       "         [-7.7914, -7.7903, -7.5948,  ..., -7.7349, -7.6338, -7.6779],\n",
       "         [-7.8136, -7.8293, -7.6232,  ..., -7.7132, -7.6454, -7.6650],\n",
       "         [-7.7944, -7.7587, -7.6250,  ..., -7.7268, -7.6518, -7.6922]],\n",
       "\n",
       "        [[-7.7499, -7.7836, -7.6080,  ..., -7.7353, -7.5779, -7.6917],\n",
       "         [-7.8164, -7.8398, -7.6145,  ..., -7.7062, -7.6056, -7.6529],\n",
       "         [-7.8001, -7.7921, -7.5763,  ..., -7.7036, -7.6084, -7.7302],\n",
       "         ...,\n",
       "         [-7.7452, -7.7275, -7.6023,  ..., -7.7856, -7.6421, -7.6724],\n",
       "         [-7.7728, -7.7601, -7.6078,  ..., -7.7558, -7.6338, -7.6875],\n",
       "         [-7.7353, -7.7251, -7.5992,  ..., -7.7919, -7.6139, -7.6510]]],\n",
       "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1e06fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 31, 2157])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eac92e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 31, 2157])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "313af945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 2157])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(a[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4aaf31d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7.1100, device='cuda:0', grad_fn=<UnbindBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(a[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0af6a61e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mlist\u001b[39;49m(a[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m])\u001b[39m.\u001b[39;49mfind(\u001b[39m-\u001b[39m\u001b[39m7.1100\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "a[0][0][0].find(-7.1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc9f8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/predi.txt',a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dcefb172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-7.6824, -7.7235, -7.5992,  ..., -7.8737, -7.7742, -7.6740],\n",
       "          [-7.6339, -7.9091, -8.0708,  ..., -7.9338, -7.5792, -7.4553],\n",
       "          [-7.8265, -7.8726, -7.8509,  ..., -7.8776, -7.6236, -7.6614],\n",
       "          ...,\n",
       "          [-7.6481, -7.7852, -7.8148,  ..., -7.8645, -7.5989, -7.5104],\n",
       "          [-7.6313, -7.7689, -7.8622,  ..., -7.8628, -7.6599, -7.5950],\n",
       "          [-7.6154, -7.7847, -7.9249,  ..., -7.8232, -7.7926, -7.5564]],\n",
       " \n",
       "         [[-7.6278, -7.6087, -7.5856,  ..., -7.7199, -7.8265, -7.7112],\n",
       "          [-7.7372, -7.7250, -8.1150,  ..., -8.0014, -7.3843, -7.6199],\n",
       "          [-7.8522, -7.8523, -7.8662,  ..., -7.9437, -7.7490, -7.7384],\n",
       "          ...,\n",
       "          [-7.6415, -7.7561, -7.8512,  ..., -7.9436, -7.6349, -7.6600],\n",
       "          [-7.6841, -7.7417, -7.8274,  ..., -7.8449, -7.6858, -7.5914],\n",
       "          [-7.5489, -7.8715, -7.9717,  ..., -7.9556, -7.6160, -7.5791]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.5231, -7.6962, -7.6010,  ..., -7.6291, -7.8367, -7.6463],\n",
       "          [-7.7704, -7.9150, -8.1951,  ..., -7.9639, -7.6326, -7.5844],\n",
       "          [-7.7677, -7.8970, -7.8867,  ..., -7.8851, -7.6881, -7.5756],\n",
       "          ...,\n",
       "          [-7.5597, -7.8589, -7.9666,  ..., -7.9278, -7.6845, -7.4809],\n",
       "          [-7.6020, -7.7914, -7.9011,  ..., -7.8780, -7.6384, -7.5225],\n",
       "          [-7.5357, -7.8541, -7.8959,  ..., -7.8381, -7.6647, -7.5412]],\n",
       " \n",
       "         [[-7.7881, -7.4921, -7.5358,  ..., -7.5553, -7.8224, -7.6138],\n",
       "          [-7.8029, -7.8516, -8.0801,  ..., -7.9848, -7.5611, -7.4602],\n",
       "          [-7.5628, -7.9815, -7.9977,  ..., -8.0865, -7.5558, -7.5534],\n",
       "          ...,\n",
       "          [-7.6199, -7.7258, -7.8623,  ..., -7.8883, -7.5511, -7.5882],\n",
       "          [-7.6097, -7.8258, -7.8786,  ..., -7.8991, -7.6393, -7.5350],\n",
       "          [-7.5894, -7.7950, -7.8099,  ..., -7.8293, -7.6529, -7.5138]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.6820, -7.5163, -7.6057,  ..., -7.5037, -7.9066, -7.7109],\n",
       "          [-7.7861, -7.8389, -8.2067,  ..., -7.9775, -7.6077, -7.6574],\n",
       "          [-7.8037, -7.9872, -8.0739,  ..., -7.9283, -7.7032, -7.6204],\n",
       "          ...,\n",
       "          [-7.6394, -7.8632, -7.9837,  ..., -7.7959, -7.6529, -7.5731],\n",
       "          [-7.5917, -7.7897, -7.8838,  ..., -7.8793, -7.7896, -7.5368],\n",
       "          [-7.5629, -7.8066, -7.9677,  ..., -7.8001, -7.7036, -7.5891]],\n",
       " \n",
       "         [[-7.6848, -7.5867, -7.6392,  ..., -7.6723, -7.8074, -7.6246],\n",
       "          [-7.7841, -7.7368, -8.0752,  ..., -7.8298, -7.5387, -7.5974],\n",
       "          [-7.8036, -7.8224, -7.9275,  ..., -7.8784, -7.6595, -7.6839],\n",
       "          ...,\n",
       "          [-7.7246, -7.7420, -7.9124,  ..., -7.8496, -7.6468, -7.6072],\n",
       "          [-7.6316, -7.7851, -7.9010,  ..., -7.8715, -7.7427, -7.5033],\n",
       "          [-7.6997, -7.7958, -7.8268,  ..., -7.7967, -7.6476, -7.6471]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.7861, -7.6957, -7.4868,  ..., -7.6224, -7.9054, -7.6776],\n",
       "          [-7.7328, -7.8147, -8.0147,  ..., -7.8800, -7.4653, -7.4983],\n",
       "          [-7.7352, -7.7556, -7.8089,  ..., -7.9594, -7.6120, -7.6732],\n",
       "          ...,\n",
       "          [-7.6881, -7.8205, -7.8870,  ..., -7.7998, -7.6898, -7.5162],\n",
       "          [-7.5654, -7.7384, -7.8908,  ..., -7.8473, -7.6368, -7.5030],\n",
       "          [-7.5868, -7.8941, -7.9899,  ..., -7.8881, -7.6683, -7.5183]],\n",
       " \n",
       "         [[-7.6819, -7.4857, -7.5680,  ..., -7.6239, -7.8721, -7.7312],\n",
       "          [-7.9112, -7.6987, -8.0090,  ..., -7.9019, -7.5006, -7.5139],\n",
       "          [-7.8029, -7.7782, -7.8483,  ..., -7.8084, -7.7057, -7.7763],\n",
       "          ...,\n",
       "          [-7.6099, -7.8661, -7.9287,  ..., -7.8185, -7.7366, -7.4274],\n",
       "          [-7.6234, -7.7615, -7.8228,  ..., -7.7722, -7.5964, -7.5546],\n",
       "          [-7.6167, -7.7874, -7.9493,  ..., -7.8409, -7.6663, -7.4716]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.6983, -7.5568, -7.5821,  ..., -7.5996, -7.7870, -7.6775],\n",
       "          [-7.7612, -7.7011, -8.1690,  ..., -8.0146, -7.6617, -7.4306],\n",
       "          [-7.7424, -7.9444, -7.9604,  ..., -7.8699, -7.6575, -7.5892],\n",
       "          ...,\n",
       "          [-7.6700, -7.7379, -7.8998,  ..., -7.8124, -7.7092, -7.6567],\n",
       "          [-7.5950, -7.7412, -7.9368,  ..., -7.7600, -7.6853, -7.5252],\n",
       "          [-7.6316, -7.7193, -8.0267,  ..., -7.9130, -7.6754, -7.6036]],\n",
       " \n",
       "         [[-7.5820, -7.6571, -7.6023,  ..., -7.6399, -7.8063, -7.6438],\n",
       "          [-7.6815, -7.7886, -8.1396,  ..., -7.9300, -7.8109, -7.6585],\n",
       "          [-7.7652, -7.8638, -8.0073,  ..., -7.9363, -7.6544, -7.6183],\n",
       "          ...,\n",
       "          [-7.6337, -7.7359, -7.9794,  ..., -7.8629, -7.7010, -7.4892],\n",
       "          [-7.6304, -7.7215, -7.9422,  ..., -7.8046, -7.6963, -7.6648],\n",
       "          [-7.5360, -7.8484, -7.9378,  ..., -7.8608, -7.7483, -7.5902]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.6458, -7.6983, -7.6746,  ..., -7.7307, -7.7997, -7.6177],\n",
       "          [-7.6148, -7.8635, -8.2458,  ..., -7.9805, -7.6270, -7.4935],\n",
       "          [-7.6649, -7.8285, -7.9638,  ..., -7.8338, -7.6748, -7.5357],\n",
       "          ...,\n",
       "          [-7.6070, -7.7982, -7.8509,  ..., -7.7188, -7.7443, -7.5910],\n",
       "          [-7.5414, -7.8776, -7.9726,  ..., -7.8879, -7.6547, -7.5874],\n",
       "          [-7.5638, -7.7944, -7.9317,  ..., -7.7821, -7.6855, -7.6252]],\n",
       " \n",
       "         [[-7.5567, -7.5805, -7.5855,  ..., -7.5409, -7.8642, -7.6373],\n",
       "          [-7.8221, -7.6618, -7.9692,  ..., -7.9148, -7.4639, -7.5354],\n",
       "          [-7.7383, -7.8913, -7.9007,  ..., -7.8525, -7.6255, -7.6975],\n",
       "          ...,\n",
       "          [-7.6563, -7.8847, -7.9071,  ..., -7.8572, -7.7263, -7.4914],\n",
       "          [-7.6017, -7.8498, -7.9658,  ..., -7.9166, -7.6401, -7.5400],\n",
       "          [-7.5421, -7.8425, -7.9040,  ..., -7.7403, -7.6565, -7.5835]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.5340, -7.6677, -7.5310,  ..., -7.5054, -7.8784, -7.6513],\n",
       "          [-7.5020, -7.9157, -8.2659,  ..., -7.9548, -7.6437, -7.4767],\n",
       "          [-7.8638, -7.9051, -7.8709,  ..., -7.7669, -7.7202, -7.6973],\n",
       "          ...,\n",
       "          [-7.6053, -7.8419, -7.9171,  ..., -7.8045, -7.6022, -7.6153],\n",
       "          [-7.6317, -7.7706, -7.9847,  ..., -7.8037, -7.5953, -7.5942],\n",
       "          [-7.5147, -7.8185, -7.9845,  ..., -7.8348, -7.7098, -7.4629]],\n",
       " \n",
       "         [[-7.7268, -7.6463, -7.5497,  ..., -7.5121, -7.8841, -7.6375],\n",
       "          [-7.7319, -7.8002, -8.3094,  ..., -7.9463, -7.4557, -7.5711],\n",
       "          [-7.6354, -7.9560, -7.8519,  ..., -7.9974, -7.6836, -7.5953],\n",
       "          ...,\n",
       "          [-7.6064, -7.7975, -7.9078,  ..., -7.8437, -7.6735, -7.5326],\n",
       "          [-7.6210, -7.8256, -7.9580,  ..., -7.9018, -7.5443, -7.6320],\n",
       "          [-7.4599, -7.8291, -7.9371,  ..., -7.7872, -7.7210, -7.4067]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.6251, -7.7653, -7.6646,  ..., -7.6907, -7.6385, -7.6017],\n",
       "          [-7.6200, -7.8336, -8.1943,  ..., -7.9470, -7.5588, -7.5374],\n",
       "          [-7.7068, -7.8938, -7.9585,  ..., -8.0276, -7.6511, -7.6894],\n",
       "          ...,\n",
       "          [-7.5664, -7.9176, -7.9248,  ..., -7.8934, -7.6245, -7.5434],\n",
       "          [-7.5661, -7.8803, -7.9245,  ..., -7.8119, -7.6371, -7.5528],\n",
       "          [-7.5700, -7.8774, -7.9625,  ..., -7.8692, -7.6861, -7.5619]],\n",
       " \n",
       "         [[-7.6872, -7.6098, -7.5681,  ..., -7.5649, -7.8251, -7.6730],\n",
       "          [-7.6445, -7.8065, -8.1870,  ..., -8.0099, -7.6147, -7.5524],\n",
       "          [-7.6379, -7.8725, -8.0158,  ..., -7.8868, -7.7714, -7.6161],\n",
       "          ...,\n",
       "          [-7.5654, -7.8161, -7.9140,  ..., -7.8248, -7.6116, -7.5537],\n",
       "          [-7.5492, -7.8225, -7.9197,  ..., -7.8215, -7.7389, -7.5284],\n",
       "          [-7.4995, -7.8735, -8.0157,  ..., -7.8309, -7.6158, -7.5691]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.4694, -7.5705, -7.5343,  ..., -7.5021, -7.9671, -7.7027],\n",
       "          [-7.6211, -7.8211, -8.0622,  ..., -7.9613, -7.5446, -7.6253],\n",
       "          [-7.7183, -7.8684, -7.9825,  ..., -7.9484, -7.5122, -7.7386],\n",
       "          ...,\n",
       "          [-7.5691, -7.9323, -7.9776,  ..., -7.8382, -7.6955, -7.5669],\n",
       "          [-7.4740, -7.9279, -7.9975,  ..., -7.7985, -7.6651, -7.5217],\n",
       "          [-7.4061, -7.9662, -7.9821,  ..., -7.7584, -7.7395, -7.5228]],\n",
       " \n",
       "         [[-7.6279, -7.5313, -7.5739,  ..., -7.6468, -7.9334, -7.5593],\n",
       "          [-7.7557, -7.8373, -8.1386,  ..., -7.8140, -7.6680, -7.5688],\n",
       "          [-7.7418, -7.8939, -7.8814,  ..., -7.8564, -7.7042, -7.5870],\n",
       "          ...,\n",
       "          [-7.5417, -7.7958, -7.8914,  ..., -7.7817, -7.6163, -7.6380],\n",
       "          [-7.5299, -7.8565, -7.9395,  ..., -7.8539, -7.6677, -7.5473],\n",
       "          [-7.5375, -7.8968, -7.9178,  ..., -7.7954, -7.6497, -7.5063]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.6033, -7.5611, -7.4397,  ..., -7.6133, -7.7874, -7.7452],\n",
       "          [-7.7101, -7.9581, -8.1514,  ..., -7.9473, -7.8155, -7.6613],\n",
       "          [-7.7205, -7.8961, -7.8129,  ..., -7.9252, -7.7319, -7.6648],\n",
       "          ...,\n",
       "          [-7.4884, -7.7887, -8.0712,  ..., -7.8850, -7.7100, -7.5426],\n",
       "          [-7.6473, -7.8981, -7.9495,  ..., -7.8550, -7.7310, -7.5843],\n",
       "          [-7.4504, -7.8514, -8.0727,  ..., -7.8417, -7.6463, -7.5219]],\n",
       " \n",
       "         [[-7.5328, -7.7416, -7.6309,  ..., -7.5396, -7.8891, -7.5564],\n",
       "          [-7.3559, -7.9181, -8.0013,  ..., -7.9378, -7.5656, -7.3315],\n",
       "          [-7.5856, -7.9876, -7.8995,  ..., -7.9238, -7.5328, -7.5653],\n",
       "          ...,\n",
       "          [-7.5820, -7.8519, -7.9527,  ..., -7.8460, -7.7343, -7.6040],\n",
       "          [-7.5397, -7.8792, -7.8061,  ..., -7.8147, -7.7502, -7.5981],\n",
       "          [-7.5824, -7.8371, -7.9575,  ..., -7.8423, -7.5764, -7.5278]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.4783, -7.7045, -7.4962,  ..., -7.7270, -7.8653, -7.5980],\n",
       "          [-7.4310, -7.9010, -8.1878,  ..., -7.9161, -7.5016, -7.5255],\n",
       "          [-7.5936, -7.9901, -8.0288,  ..., -7.9323, -7.7204, -7.6226],\n",
       "          ...,\n",
       "          [-7.6347, -7.7038, -7.8367,  ..., -7.7812, -7.7087, -7.5878],\n",
       "          [-7.5204, -7.7859, -7.9959,  ..., -7.8178, -7.7259, -7.6281],\n",
       "          [-7.5730, -7.7477, -7.9314,  ..., -7.8389, -7.5981, -7.5672]],\n",
       " \n",
       "         [[-7.6437, -7.6333, -7.5277,  ..., -7.5807, -7.8500, -7.7374],\n",
       "          [-7.7331, -7.9076, -8.1496,  ..., -8.0079, -7.6721, -7.4733],\n",
       "          [-7.7038, -8.0008, -7.9221,  ..., -7.9405, -7.7126, -7.6427],\n",
       "          ...,\n",
       "          [-7.5029, -7.9958, -7.8849,  ..., -7.8350, -7.6604, -7.4349],\n",
       "          [-7.4327, -7.8648, -7.9726,  ..., -7.7853, -7.6359, -7.5863],\n",
       "          [-7.5969, -7.7931, -8.0177,  ..., -7.8315, -7.6924, -7.6675]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.5224, -7.6834, -7.5753,  ..., -7.4575, -7.9286, -7.7226],\n",
       "          [-7.7999, -7.6932, -7.9228,  ..., -7.9977, -7.5978, -7.5337],\n",
       "          [-7.9233, -7.9018, -7.7667,  ..., -7.8185, -7.6067, -7.8490],\n",
       "          ...,\n",
       "          [-7.6008, -7.7370, -7.9316,  ..., -7.8206, -7.6464, -7.5761],\n",
       "          [-7.6327, -7.7704, -7.9051,  ..., -7.8796, -7.6708, -7.6212],\n",
       "          [-7.5958, -7.7927, -7.8708,  ..., -7.8229, -7.6835, -7.6202]],\n",
       " \n",
       "         [[-7.4898, -7.7134, -7.6771,  ..., -7.7301, -7.8176, -7.7051],\n",
       "          [-7.7262, -7.7761, -8.0434,  ..., -7.8798, -7.7066, -7.5910],\n",
       "          [-7.6000, -7.9065, -7.8901,  ..., -7.9276, -7.8054, -7.5206],\n",
       "          ...,\n",
       "          [-7.5454, -7.8246, -7.9156,  ..., -7.8460, -7.8132, -7.4588],\n",
       "          [-7.5715, -7.7863, -7.9963,  ..., -7.8826, -7.7221, -7.5493],\n",
       "          [-7.6211, -7.8609, -7.8563,  ..., -7.7848, -7.7432, -7.5376]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.5403, -7.6309, -7.4013,  ..., -7.5220, -7.8571, -7.5105],\n",
       "          [-7.6543, -7.8675, -8.0568,  ..., -8.0272, -7.7012, -7.6782],\n",
       "          [-7.7537, -7.9600, -7.9907,  ..., -7.9473, -7.7047, -7.5993],\n",
       "          ...,\n",
       "          [-7.6725, -7.8874, -7.8101,  ..., -7.8020, -7.5361, -7.6240],\n",
       "          [-7.6685, -7.7755, -7.9684,  ..., -7.9024, -7.6122, -7.5822],\n",
       "          [-7.7265, -7.8996, -7.8761,  ..., -7.9515, -7.6374, -7.4811]],\n",
       " \n",
       "         [[-7.6312, -7.6458, -7.4785,  ..., -7.7504, -7.7956, -7.6304],\n",
       "          [-7.7577, -7.7472, -8.1457,  ..., -8.0487, -7.6159, -7.5963],\n",
       "          [-7.7099, -7.8753, -7.9848,  ..., -7.9496, -7.6702, -7.6600],\n",
       "          ...,\n",
       "          [-7.6904, -7.7642, -7.8811,  ..., -7.8624, -7.6170, -7.4712],\n",
       "          [-7.6754, -7.8275, -7.9635,  ..., -7.9100, -7.6894, -7.6152],\n",
       "          [-7.6444, -7.7826, -7.8270,  ..., -7.7375, -7.7100, -7.5999]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.7366, -7.4512, -7.4696,  ..., -7.6128, -7.7740, -7.6344],\n",
       "          [-7.7818, -7.7149, -7.9494,  ..., -7.8907, -7.6163, -7.6217],\n",
       "          [-7.8708, -7.8356, -7.8680,  ..., -7.9284, -7.7136, -7.6131],\n",
       "          ...,\n",
       "          [-7.6816, -7.7006, -7.8923,  ..., -7.7526, -7.6397, -7.6231],\n",
       "          [-7.5668, -7.7712, -7.8740,  ..., -7.7760, -7.5929, -7.5800],\n",
       "          [-7.7246, -7.7198, -7.9506,  ..., -7.8395, -7.5297, -7.5761]],\n",
       " \n",
       "         [[-7.6690, -7.5511, -7.4050,  ..., -7.5665, -7.8371, -7.7022],\n",
       "          [-7.7198, -7.8313, -7.9738,  ..., -7.9597, -7.4378, -7.4252],\n",
       "          [-7.6222, -7.9026, -8.0325,  ..., -7.8770, -7.7020, -7.5348],\n",
       "          ...,\n",
       "          [-7.6483, -7.7728, -7.9673,  ..., -7.9136, -7.6472, -7.5499],\n",
       "          [-7.5856, -7.9481, -7.9458,  ..., -7.9291, -7.6223, -7.4288],\n",
       "          [-7.6500, -7.8326, -7.9381,  ..., -7.8758, -7.5190, -7.5137]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.5588, -7.6819, -7.6412,  ..., -7.5831, -7.7246, -7.6088],\n",
       "          [-7.7682, -7.6916, -8.1081,  ..., -7.9365, -7.4336, -7.5000],\n",
       "          [-7.7856, -7.8221, -7.8726,  ..., -8.1090, -7.6869, -7.5868],\n",
       "          ...,\n",
       "          [-7.7483, -7.8517, -7.9329,  ..., -7.8941, -7.6861, -7.5458],\n",
       "          [-7.6193, -7.9927, -7.9593,  ..., -8.0468, -7.5840, -7.5014],\n",
       "          [-7.5637, -7.7467, -8.0111,  ..., -7.9125, -7.5949, -7.5931]],\n",
       " \n",
       "         [[-7.6340, -7.5824, -7.5393,  ..., -7.7081, -7.7797, -7.6664],\n",
       "          [-7.7577, -7.9184, -8.0823,  ..., -7.7745, -7.5882, -7.4948],\n",
       "          [-7.8851, -7.9182, -7.7590,  ..., -7.9721, -7.6634, -7.6222],\n",
       "          ...,\n",
       "          [-7.6917, -7.8609, -7.9578,  ..., -7.8914, -7.6583, -7.4625],\n",
       "          [-7.7944, -7.7434, -7.8845,  ..., -7.9251, -7.6437, -7.4888],\n",
       "          [-7.6836, -7.8714, -8.0109,  ..., -7.9117, -7.6115, -7.5128]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.7355, -7.4648, -7.4616,  ..., -7.5885, -7.7881, -7.7774],\n",
       "          [-8.0339, -7.5408, -7.8892,  ..., -8.0665, -7.5585, -7.6299],\n",
       "          [-7.8098, -7.8298, -7.9488,  ..., -7.9839, -7.5920, -7.6812],\n",
       "          ...,\n",
       "          [-7.7132, -7.7368, -7.9521,  ..., -7.8090, -7.6637, -7.6826],\n",
       "          [-7.6029, -7.7706, -7.8658,  ..., -7.8280, -7.6738, -7.5190],\n",
       "          [-7.6643, -7.8275, -7.8599,  ..., -7.8866, -7.6138, -7.5310]],\n",
       " \n",
       "         [[-7.6439, -7.5204, -7.5514,  ..., -7.6875, -7.6417, -7.6938],\n",
       "          [-7.8868, -7.7962, -8.1140,  ..., -7.9337, -7.6336, -7.5189],\n",
       "          [-7.9803, -7.9314, -7.8604,  ..., -7.9919, -7.6367, -7.6670],\n",
       "          ...,\n",
       "          [-7.7083, -7.7978, -7.8526,  ..., -7.8411, -7.5777, -7.5604],\n",
       "          [-7.7663, -7.8295, -7.9298,  ..., -7.9051, -7.6504, -7.4452],\n",
       "          [-7.7302, -7.8685, -8.0313,  ..., -7.9374, -7.5913, -7.4865]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.5504, -7.6496, -7.6450,  ..., -7.6271, -7.7189, -7.6196],\n",
       "          [-7.6231, -7.9516, -8.2438,  ..., -8.0037, -7.6947, -7.5494],\n",
       "          [-7.8527, -7.8377, -7.9001,  ..., -7.9292, -7.7539, -7.6196],\n",
       "          ...,\n",
       "          [-7.6309, -7.8159, -7.9615,  ..., -7.8377, -7.7058, -7.5680],\n",
       "          [-7.6525, -7.7947, -7.9824,  ..., -7.8589, -7.6458, -7.5179],\n",
       "          [-7.7466, -7.8796, -7.8323,  ..., -7.8468, -7.6672, -7.5788]],\n",
       " \n",
       "         [[-7.5449, -7.5891, -7.6289,  ..., -7.5536, -7.7741, -7.6936],\n",
       "          [-7.8386, -7.7076, -8.0918,  ..., -7.8825, -7.5459, -7.6705],\n",
       "          [-7.8228, -7.7771, -7.8246,  ..., -7.8530, -7.8158, -7.6192],\n",
       "          ...,\n",
       "          [-7.7440, -7.8732, -7.8767,  ..., -7.8126, -7.6227, -7.5971],\n",
       "          [-7.6139, -7.8257, -7.9695,  ..., -7.9190, -7.5897, -7.5307],\n",
       "          [-7.7193, -7.6171, -7.9140,  ..., -7.8239, -7.6557, -7.6077]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.4745, -7.7114, -7.5790,  ..., -7.6020, -7.8154, -7.7580],\n",
       "          [-7.9522, -7.6480, -8.2140,  ..., -7.9739, -7.6832, -7.7692],\n",
       "          [-7.8149, -7.5515, -7.5688,  ..., -7.8933, -7.7244, -7.6460],\n",
       "          ...,\n",
       "          [-7.5374, -7.7958, -7.9906,  ..., -7.8891, -7.6107, -7.5307],\n",
       "          [-7.6249, -7.8357, -7.9668,  ..., -7.8752, -7.6931, -7.6017],\n",
       "          [-7.6576, -7.7398, -7.8640,  ..., -7.8550, -7.6316, -7.6309]],\n",
       " \n",
       "         [[-7.6826, -7.6356, -7.5129,  ..., -7.6668, -7.8068, -7.6595],\n",
       "          [-7.7953, -7.6218, -8.0682,  ..., -7.8640, -7.5706, -7.5266],\n",
       "          [-7.9252, -7.6507, -7.8162,  ..., -7.9133, -7.6914, -7.7415],\n",
       "          ...,\n",
       "          [-7.6841, -7.7764, -7.9362,  ..., -7.8361, -7.7278, -7.6067],\n",
       "          [-7.6216, -7.7647, -7.9633,  ..., -7.7925, -7.7157, -7.5905],\n",
       "          [-7.5912, -7.8587, -7.9036,  ..., -7.8637, -7.7666, -7.5568]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.6689, -7.5703, -7.5049,  ..., -7.5633, -7.9067, -7.7482],\n",
       "          [-7.7360, -7.8169, -8.1154,  ..., -8.0050, -7.7535, -7.6247],\n",
       "          [-7.6965, -7.8876, -7.8462,  ..., -7.8435, -7.7915, -7.7077],\n",
       "          ...,\n",
       "          [-7.6162, -7.8664, -7.8365,  ..., -7.8142, -7.7269, -7.4995],\n",
       "          [-7.6308, -7.8086, -7.8579,  ..., -7.8583, -7.7098, -7.4945],\n",
       "          [-7.6305, -7.7976, -7.8641,  ..., -7.8245, -7.6594, -7.5285]],\n",
       " \n",
       "         [[-7.7425, -7.5102, -7.4639,  ..., -7.5530, -7.7881, -7.7147],\n",
       "          [-7.7532, -7.7426, -8.0470,  ..., -7.8157, -7.6159, -7.6339],\n",
       "          [-7.6387, -7.7805, -7.7790,  ..., -7.8678, -7.8419, -7.6147],\n",
       "          ...,\n",
       "          [-7.5920, -7.7978, -7.8643,  ..., -7.8428, -7.6169, -7.5021],\n",
       "          [-7.6494, -7.9384, -7.8981,  ..., -7.8483, -7.7280, -7.4183],\n",
       "          [-7.7100, -7.8504, -7.9781,  ..., -7.8948, -7.6303, -7.5773]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.5452, -7.6483, -7.4722,  ..., -7.6533, -7.6649, -7.6795],\n",
       "          [-7.7287, -7.8438, -8.0481,  ..., -7.9236, -7.5825, -7.5547],\n",
       "          [-7.6569, -7.9803, -7.9483,  ..., -7.9003, -7.7780, -7.5935],\n",
       "          ...,\n",
       "          [-7.6572, -7.7352, -7.9492,  ..., -7.8315, -7.7220, -7.6063],\n",
       "          [-7.5440, -7.7439, -7.9304,  ..., -7.8106, -7.6306, -7.5983],\n",
       "          [-7.4864, -7.8413, -8.0046,  ..., -7.8897, -7.6649, -7.4746]],\n",
       " \n",
       "         [[-7.7216, -7.5237, -7.4283,  ..., -7.6598, -7.8629, -7.7334],\n",
       "          [-7.6685, -7.8565, -8.0453,  ..., -7.8677, -7.6161, -7.5612],\n",
       "          [-7.8058, -7.9157, -7.8417,  ..., -7.9016, -7.7192, -7.6486],\n",
       "          ...,\n",
       "          [-7.6191, -7.8714, -7.8847,  ..., -7.8510, -7.6965, -7.4992],\n",
       "          [-7.5395, -7.8420, -7.9042,  ..., -7.8315, -7.7654, -7.5304],\n",
       "          [-7.5303, -7.8849, -7.8680,  ..., -7.8637, -7.6977, -7.6341]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.5631, -7.6015, -7.3830,  ..., -7.4686, -7.9374, -7.6868],\n",
       "          [-7.7063, -7.8556, -8.1146,  ..., -7.9941, -7.5186, -7.5589],\n",
       "          [-7.6363, -8.0048, -8.0147,  ..., -7.9784, -7.6057, -7.5668],\n",
       "          ...,\n",
       "          [-7.6077, -7.8311, -7.9788,  ..., -7.8266, -7.6646, -7.5431],\n",
       "          [-7.4920, -7.8862, -7.9584,  ..., -7.8613, -7.5875, -7.5402],\n",
       "          [-7.6188, -7.8827, -7.9388,  ..., -7.9055, -7.7110, -7.4696]],\n",
       " \n",
       "         [[-7.6168, -7.5897, -7.4210,  ..., -7.5337, -7.9143, -7.7518],\n",
       "          [-7.7497, -7.8827, -8.0782,  ..., -7.8801, -7.7127, -7.6882],\n",
       "          [-7.6470, -7.7574, -7.9365,  ..., -7.8860, -7.8052, -7.6465],\n",
       "          ...,\n",
       "          [-7.6128, -7.8115, -7.9200,  ..., -7.7725, -7.7071, -7.6293],\n",
       "          [-7.6162, -7.8114, -7.8807,  ..., -7.7966, -7.6414, -7.5564],\n",
       "          [-7.5916, -7.8339, -7.8038,  ..., -7.7491, -7.6069, -7.5574]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.5203, -7.6181, -7.5432,  ..., -7.5989, -7.8261, -7.7088],\n",
       "          [-7.6587, -7.8668, -8.1849,  ..., -7.8695, -7.5504, -7.5731],\n",
       "          [-7.8489, -7.7703, -7.6237,  ..., -7.8653, -7.7401, -7.6280],\n",
       "          ...,\n",
       "          [-7.6547, -7.8504, -7.9979,  ..., -7.8676, -7.7247, -7.5816],\n",
       "          [-7.6669, -7.7604, -7.8620,  ..., -7.8139, -7.6076, -7.5714],\n",
       "          [-7.6389, -7.7328, -7.9458,  ..., -7.9202, -7.6741, -7.4484]],\n",
       " \n",
       "         [[-7.4764, -7.7591, -7.6678,  ..., -7.6484, -7.8394, -7.5578],\n",
       "          [-7.7068, -7.8409, -8.1256,  ..., -7.9403, -7.5690, -7.4955],\n",
       "          [-7.8911, -7.9637, -7.8806,  ..., -8.0474, -7.5360, -7.7870],\n",
       "          ...,\n",
       "          [-7.6823, -7.7279, -7.8767,  ..., -7.7965, -7.7885, -7.6661],\n",
       "          [-7.6044, -7.8578, -7.9722,  ..., -7.8445, -7.7171, -7.4972],\n",
       "          [-7.6575, -7.7860, -7.9212,  ..., -7.8921, -7.5179, -7.5748]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.5892, -7.6102, -7.5243,  ..., -7.5819, -7.8455, -7.6536],\n",
       "          [-7.6658, -7.8584, -8.1240,  ..., -7.8471, -7.5437, -7.5961],\n",
       "          [-7.5702, -8.0572, -7.9350,  ..., -7.8947, -7.6418, -7.5214],\n",
       "          ...,\n",
       "          [-7.6855, -7.9384, -7.9859,  ..., -7.9735, -7.6445, -7.5977],\n",
       "          [-7.5522, -7.8704, -7.9561,  ..., -7.8979, -7.6316, -7.4496],\n",
       "          [-7.5127, -7.8693, -8.0064,  ..., -7.8446, -7.6492, -7.5388]],\n",
       " \n",
       "         [[-7.5488, -7.7230, -7.5850,  ..., -7.5845, -7.8214, -7.6983],\n",
       "          [-7.7358, -7.8961, -8.1932,  ..., -8.0050, -7.6151, -7.5661],\n",
       "          [-7.6596, -7.8764, -7.9560,  ..., -7.8713, -7.8233, -7.6447],\n",
       "          ...,\n",
       "          [-7.6326, -7.9456, -7.8648,  ..., -7.9153, -7.6453, -7.5185],\n",
       "          [-7.6199, -7.8424, -7.9216,  ..., -7.9211, -7.6638, -7.5177],\n",
       "          [-7.6266, -7.8877, -7.9791,  ..., -7.8920, -7.5809, -7.5649]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.6235, -7.4809, -7.4919,  ..., -7.4526, -7.9339, -7.7462],\n",
       "          [-7.7202, -7.7945, -8.0132,  ..., -7.9686, -7.7011, -7.6930],\n",
       "          [-7.8007, -7.9113, -7.7755,  ..., -7.9024, -7.5268, -7.5979],\n",
       "          ...,\n",
       "          [-7.6937, -7.8996, -7.9604,  ..., -7.9246, -7.6578, -7.4900],\n",
       "          [-7.5958, -7.9409, -7.9555,  ..., -7.9331, -7.7001, -7.4409],\n",
       "          [-7.5189, -7.9157, -8.0691,  ..., -7.8804, -7.6714, -7.4151]],\n",
       " \n",
       "         [[-7.6469, -7.5702, -7.6146,  ..., -7.5689, -7.8528, -7.7043],\n",
       "          [-7.9940, -7.8070, -8.0553,  ..., -8.0515, -7.5459, -7.5998],\n",
       "          [-7.7033, -7.8724, -8.0382,  ..., -7.9325, -7.6155, -7.7542],\n",
       "          ...,\n",
       "          [-7.6877, -7.8212, -7.8653,  ..., -7.8651, -7.7115, -7.5605],\n",
       "          [-7.6184, -7.9434, -7.9956,  ..., -7.9132, -7.5799, -7.5488],\n",
       "          [-7.5634, -7.7656, -7.9179,  ..., -7.7515, -7.5762, -7.4858]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[-7.7621, -7.5824, -7.4619,  ..., -7.6661, -7.7476, -7.8106],\n",
       "          [-7.8552, -7.8600, -8.1457,  ..., -8.0118, -7.5762, -7.5497],\n",
       "          [-7.7581, -7.8862, -7.9291,  ..., -7.9229, -7.6488, -7.5863],\n",
       "          ...,\n",
       "          [-7.5783, -7.8815, -7.8467,  ..., -7.7028, -7.6862, -7.6171],\n",
       "          [-7.5339, -7.8857, -7.9415,  ..., -7.8491, -7.7186, -7.4674],\n",
       "          [-7.6158, -7.8419, -8.0029,  ..., -7.8446, -7.5364, -7.6532]],\n",
       " \n",
       "         [[-7.5688, -7.5938, -7.5650,  ..., -7.6271, -7.8118, -7.6486],\n",
       "          [-7.9422, -7.8888, -8.0364,  ..., -8.0557, -7.5449, -7.6594],\n",
       "          [-7.8515, -7.9439, -7.9993,  ..., -7.9063, -7.5881, -7.6166],\n",
       "          ...,\n",
       "          [-7.6287, -7.7479, -8.1106,  ..., -7.9406, -7.5511, -7.5575],\n",
       "          [-7.4527, -7.8341, -8.0196,  ..., -7.8322, -7.6441, -7.5163],\n",
       "          [-7.6877, -7.8166, -7.9672,  ..., -7.9247, -7.6907, -7.5269]]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9d4d9adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0,  0,  0,  ...,  0, 24,  1],\n",
       "         [ 0,  0,  0,  ...,  0,  1, 12]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  0, 30],\n",
       "         [ 0,  0,  0,  ...,  0,  6, 27]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  1,  1],\n",
       "         [ 0,  0,  0,  ...,  0, 20,  9]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  9, 26],\n",
       "         [ 0,  0,  0,  ...,  0, 30, 21]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0, 30, 25],\n",
       "         [ 0,  0,  0,  ...,  0,  1, 15]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0, 12, 23],\n",
       "         [ 0,  0,  0,  ...,  0, 11, 27]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  2, 14],\n",
       "         [ 0,  0,  0,  ...,  0, 30,  1]], device='cuda:0'),\n",
       " tensor([[27,  0,  0,  ...,  0, 30, 10],\n",
       "         [ 0,  0,  0,  ...,  0, 18,  1]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  0, 10],\n",
       "         [ 0,  0,  0,  ...,  0,  0, 26]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0, 23, 30],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  2]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0, 24,  8],\n",
       "         [ 0,  0,  0,  ...,  0, 30, 30]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0, 29, 25],\n",
       "         [ 0,  0,  0,  ...,  0,  0, 19]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  0, 28],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  1]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0, 27, 20],\n",
       "         [ 0,  0,  0,  ...,  0, 12,  9]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0, 11, 23],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  1]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0, 28, 11],\n",
       "         [ 0,  0,  0,  ...,  0, 25,  1]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0, 25,  9],\n",
       "         [ 0,  0,  0,  ...,  0, 29, 28]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  0, 26],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  9]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  0, 12],\n",
       "         [ 0,  0,  0,  ...,  0, 29, 20]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  0,  1],\n",
       "         [ 0,  0,  0,  ...,  0,  0, 25]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  1, 23],\n",
       "         [ 0,  0,  0,  ...,  0, 21,  1]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  0,  1],\n",
       "         [ 0,  0,  0,  ...,  0, 12, 12]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  0,  9],\n",
       "         [ 0,  0,  0,  ...,  0, 28,  2]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  0,  1],\n",
       "         [ 0,  0,  0,  ...,  0,  0, 26]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  ...,  0,  0, 30],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  9]], device='cuda:0')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8445ade3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ...,  0, 24,  1],\n",
       "        [ 0,  0,  0,  ...,  0,  1, 12]], device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "23efcbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30, device='cuda:0')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(b[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91937371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
